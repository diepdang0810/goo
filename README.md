# Go1 Project

A modular Clean Architecture Golang project with integrated observability and event-driven architecture.

## Features

- **Clean Architecture**: Separation of concerns with Domain, Application, Infrastructure, and Presentation layers
- **Event-Driven**: Kafka integration for async messaging
- **CDC-Based Caching**:
  - Debezium Change Data Capture for automatic cache synchronization
  - Redis cache-first read pattern with auto-invalidation
  - Zero manual cache management
- **Observability**:
  - Prometheus for metrics
  - Grafana for visualization
  - Jaeger for distributed tracing
  - OpenTelemetry instrumentation
- **Middleware**: CORS, Authentication (bypass mode), Metrics, Tracing
- **Error Handling**: Structured error responses with custom error codes
- **Database**: PostgreSQL with migrations and logical replication
- **Development**: Hot reload with Air

## Tech Stack

- **Go**: 1.25.4
- **Web Framework**: Gin
- **Database**: PostgreSQL 15 (with CDC via logical replication)
- **Caching**: Redis 7
- **Message Queue**: Kafka (Confluent 7.3.1)
- **CDC**: Debezium 2.5 (Kafka Connect + PostgreSQL connector)
- **Observability**: Prometheus, Grafana, Jaeger, OpenTelemetry
- **Config**: Viper
- **Logging**: Zap

## Project Structure

```
.
â”œâ”€â”€ cmd
â”‚   â”œâ”€â”€ app                      # API server entry point
â”‚   â”‚   â””â”€â”€ main.go
â”‚   â””â”€â”€ worker                   # Worker entry point
â”‚       â””â”€â”€ main.go
â”œâ”€â”€ config                       # Configuration files
â”‚   â”œâ”€â”€ config.yaml             # Main config file
â”‚   â”œâ”€â”€ config.go               # Config loader
â”‚   â”œâ”€â”€ app.go                  # App config struct
â”‚   â”œâ”€â”€ postgres.go             # Postgres config
â”‚   â”œâ”€â”€ redis.go                # Redis config
â”‚   â”œâ”€â”€ kafka.go                # Kafka config
â”‚   â””â”€â”€ jaeger.go               # Jaeger config
â”œâ”€â”€ internal
â”‚   â”œâ”€â”€ api                      # API Service
â”‚   â”‚   â”œâ”€â”€ server              # HTTP server setup & middleware
â”‚   â”‚   â””â”€â”€ handlers            # HTTP handlers (Presentation Layer)
â”‚   â”‚       â””â”€â”€ order
â”‚   â”‚           â”œâ”€â”€ handler.go  # Order HTTP handlers
â”‚   â”‚           â”œâ”€â”€ dto.go      # Request/Response DTOs
â”‚   â”‚           â””â”€â”€ router.go   # Route definitions
â”‚   â”œâ”€â”€ worker                   # Worker Service  
â”‚   â”‚   â”œâ”€â”€ worker.go           # Worker orchestration
â”‚   â”‚   â””â”€â”€ handlers            # Message handlers
â”‚   â”‚       â””â”€â”€ order_created.go # Order created event handler
â”‚   â””â”€â”€ modules                  # Shared Business Logic
â”‚       â””â”€â”€ order               # Order Module (Clean Architecture)
â”‚           â”œâ”€â”€ application      # Application Layer
â”‚           â”‚   â”œâ”€â”€ dto.go      # Input/Output DTOs
â”‚           â”‚   â””â”€â”€ usecase.go  # Business logic
â”‚           â”œâ”€â”€ domain           # Domain Layer
â”‚           â”‚   â”œâ”€â”€ entity.go   # Domain entities
â”‚           â”‚   â”œâ”€â”€ repository.go # Repository interfaces
â”‚           â”‚   â”œâ”€â”€ cache.go    # Cache interfaces
â”‚           â”‚   â””â”€â”€ event.go    # Event interfaces
â”‚           â”œâ”€â”€ infrastructure   # Infrastructure Layer
â”‚           â”‚   â”œâ”€â”€ caching
â”‚           â”‚   â”‚   â”œâ”€â”€ model   # Cache models
â”‚           â”‚   â”‚   â”œâ”€â”€ mapper  # Cache mappers
â”‚           â”‚   â”‚   â””â”€â”€ redis.go # Redis implementation
â”‚           â”‚   â”œâ”€â”€ message_queue
â”‚           â”‚   â”‚   â””â”€â”€ kafka.go # Kafka implementation
â”‚           â”‚   â””â”€â”€ repository
â”‚           â”‚       â”œâ”€â”€ model   # DB models
â”‚           â”‚      â”œâ”€â”€ mapper  # DB mappers
â”‚           â”‚       â””â”€â”€ postgres.go # Postgres implementation
â”‚           â””â”€â”€ module.go       # Dependency injection
â”œâ”€â”€ migrations                   # SQL migrations
â”œâ”€â”€ pkg                         # Shared packages
â”‚   â”œâ”€â”€ apperrors               # Custom error types
â”‚   â”œâ”€â”€ kafka                   # Kafka client (producer & consumer)
â”‚   â”œâ”€â”€ logger                  # Logging utilities
â”‚   â”œâ”€â”€ metrics                 # Prometheus metrics
â”‚   â”œâ”€â”€ middleware              # HTTP middleware
â”‚   â”œâ”€â”€ postgres                # PostgreSQL client
â”‚   â”œâ”€â”€ redis                   # Redis client
â”‚   â”œâ”€â”€ response                # Standard API responses
â”‚   â”œâ”€â”€ telemetry               # OpenTelemetry setup
â”‚   â””â”€â”€ utils                   # Utility functions
â”œâ”€â”€ prometheus.yml              # Prometheus configuration
â”œâ”€â”€ Dockerfile                  # Multi-service Dockerfile
â””â”€â”€ docker-compose.yml          # Docker services
```

## Prerequisites

- Go 1.25+
- Docker & Docker Compose
- Make (optional, but recommended)

## Complete Setup & Running Guide

### Step 1: Start Infrastructure

```bash
make up
```

This starts all required services:
- PostgreSQL (port 5432) - with WAL logical replication
- Redis (port 6379)
- Kafka (port 9099)
- Zookeeper (port 2181)
- Debezium (port 8083) - CDC connector runtime (Kafka Connect API)
- Kafka Console (port 8084) - Redpanda Console UI
- Prometheus (port 9090)
- Grafana (port 3000)
- Jaeger (port 16686)

**Verify services are running:**
```bash
docker ps
```

### Step 2: Run Database Migrations

```bash
make migrate-up
```

This creates the required database tables.

### Step 2.5: Setup Debezium CDC (Optional but Recommended)

**Register the Debezium connector for automatic cache synchronization:**

```bash
./scripts/debezium/register-connector.sh
```

This enables Change Data Capture (CDC) so any PostgreSQL changes automatically sync to Redis cache.

**Verify connector status:**
```bash
./scripts/debezium/check-connector.sh
```

You should see `"state": "RUNNING"` in the output.

ğŸ“š **For detailed CDC documentation**, see: [docs/CDC_REDIS_SYNC.md](docs/CDC_REDIS_SYNC.md)

### Step 3: Start the Services

You need **TWO terminals**:

**Terminal 1 - Start API Server:**
```bash
make run
# or with hot reload (recommended for development):
make dev
```

Wait for the log:
```
âœ… Connected to PostgreSQL
âœ… Connected to Redis
âœ… Connected to Kafka producer
Server is running on :8080
```

**Terminal 2 - Start Worker:**
```bash
make run-worker
```

Wait for the log:
```
âœ… Connected to PostgreSQL
âœ… Connected to Redis
âœ… Connected to Kafka producer
Worker started
```

### Step 4: Test the Setup

**Test API:**
```bash
curl http://localhost:8080/orders/ORDER_ID
```

**Create an order (will publish event to Kafka):**
```bash
curl -X POST http://localhost:8080/orders \
  -H "Content-Type: application/json" \
  -d '{
    "service_id": 1,
    "service_type": "delivery",
    "customer_id": "cust_123",
    "points": [{"lat": 10.0, "lng": 106.0, "type": "pickup"}]
  }'
```

**Check Worker logs** - you should see:
```
ğŸ“¥ Processing message
  topic: order_created
  ...
âœ… Message processed successfully
```

### Step 5: Monitor

- **API Metrics**: http://localhost:8080/metrics
- **Prometheus**: http://localhost:9090
- **Grafana**: http://localhost:3000 (admin/admin)
- **Jaeger Tracing**: http://localhost:16686
- **Kafka Console UI**: http://localhost:8084
- **Debezium API**: http://localhost:8083 (Kafka Connect REST API)

### Stopping

**Stop services gracefully:**
- Press `Ctrl+C` in Terminal 1 (API)
- Press `Ctrl+C` in Terminal 2 (Worker)

**Stop infrastructure:**
```bash
make down
```

## Running the Application

The project has **two services** that need to be run separately:
1. **API Server** (`cmd/app`) - HTTP REST API on port 8080
2. **Worker** (`cmd/worker`) - Kafka message consumer

### Quick Start (Recommended)

**Terminal 1 - API Server:**
```bash
make run
# or with hot reload:
make dev
```

**Terminal 2 - Worker:**
```bash
make run-worker
```

The API will be available at: http://localhost:8080

### Alternative Methods

#### Method 1: Using Go directly

**Terminal 1 - API Server:**
```bash
go run cmd/app/main.go
```

**Terminal 2 - Worker:**
```bash
go run cmd/worker/main.go
```

#### Method 2: Build and run binaries

**Build both services:**
```bash
make build-all
# or separately:
make build        # builds bin/app
make build-worker # builds bin/worker
```

**Run the binaries:**

**Terminal 1:**
```bash
./bin/app
```

**Terminal 2:**
```bash
./bin/worker
```

### Important Notes

- âš ï¸ **Both services must run simultaneously** for full functionality
- âš ï¸ **Start infrastructure first** with `make up` before running services
- âš ï¸ **Run migrations** with `make migrate-up` before first use
- âœ… API server logs will show on Terminal 1
- âœ… Worker logs will show on Terminal 2

## Configuration

Configuration is managed via `config/config.yaml`. You can also override settings using environment variables (e.g., `APP_PORT=9090`).

```yaml
app:
  name: go1
  port: 8080
  env: development

postgres:
  host: localhost
  port: 5432
  # ...

redis:
  addr: localhost:6379

kafka:
  brokers: localhost:9099

jaeger:
  endpoint: localhost:4318
```

## API Endpoints

### Order Management
- `POST /orders`: Create an order
- `GET /orders/:id`: Get order by ID

### Observability
- `GET /metrics`: Prometheus metrics endpoint

## Observability & Monitoring

### Prometheus
- **URL**: http://localhost:9090
- **Metrics**: Request count, duration, active requests (CCU)

### Grafana
- **URL**: http://localhost:3000
- **Credentials**: admin/admin
- **Data Source**: Prometheus (http://prometheus:9090)

### Jaeger
- **URL**: http://localhost:16686
- **Features**: Distributed tracing for all HTTP requests

### Redpanda Console (Kafka UI)
- **URL**: http://localhost:8083
- **Features**: View topics, messages, consumer groups

## Error Handling

The application uses structured error responses:

```json
{
  "success": false,
  "error": {
    "code": 1001,
    "message": "Email already exists"
  }
}
```

**Error Codes:**
- `1001`: Resource not found
- `1002`: Validation error

## Development

### Hot Reload
The project uses [Air](https://github.com/cosmtrek/air) for hot reloading in development mode.

### Make Commands
```bash
# Infrastructure
make up           # Start all Docker services (Postgres, Redis, Kafka, etc.)
make down         # Stop all Docker services

# API Server
make run          # Run API server
make dev          # Run API server with hot reload
make build        # Build API binary (bin/app)

# Worker
make run-worker   # Run worker
make build-worker # Build worker binary (bin/worker)

# Build both
make build-all    # Build both API and Worker binaries

# Database
make migrate-up   # Run migrations
make migrate-down # Rollback migrations

# Testing
make test         # Run all tests
```

## Architecture Principles

1. **Dependency Inversion**: All layers depend on abstractions (interfaces) defined in the domain layer
2. **Separation of Concerns**: Each layer has a single, well-defined responsibility
3. **Decoupling**: Infrastructure details (DB, cache, messaging) are isolated from business logic
4. **Testability**: Clear boundaries make unit testing straightforward
5. **Service Separation**: API and Worker services share business logic through modules but deploy independently

## Service Architecture

**API Service** (`internal/api/`)
- HTTP server with Gin
- REST endpoints
- Prometheus metrics
- OpenTelemetry tracing

**Worker Service** (`internal/worker/`)
- Kafka consumer
- Event-driven processing
- Shares domain logic with API

**Shared Modules** (`internal/modules/`)
- Business logic (application layer)
- Domain entities and interfaces
- Infrastructure implementations
- Used by both API and Worker
